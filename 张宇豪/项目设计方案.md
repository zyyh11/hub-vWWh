# 技术选型

### 1. 需要设计数据库吗？

需要设计，在场景需求中，需要存储两类数据：**结构化业务数据**（类目管理 和 FAQ管理）和 **非结构化向量数据**（将文本转换成向量）。

#### A. 关系型数据库设计 (MySQL / PostgreSQL)

关于“类目管理”和“FAQ 管理”，需要设计以下核心表：

1.  **类目表 (`faq_categories`)**
    *   `id`: 主键
    *   `parent_id`: 父类目 ID（实现一级、二级等多级类目）
    *   `name`: 类目名称
    *   `level`: 层级（1级/2级）

2.  **标准问答表 (`faq_knowledge`)** —— 核心表
    *   `id`: 主键
    *   `category_id`: 关联类目表
    *   `standard_question`: 标准提问（作为该知识点的标题）
    *   `answer`: 对应的回答（富文本或纯文本）
    *   `start_time` & `end_time`: **生效时间**（后端查询时需过滤）
    *   `status`: 状态（上架/下架）

3.  **相似问法表 (`faq_similar_questions`)** —— 扩大匹配范围
    *   `id`: 主键
    *   `knowledge_id`: 关联标准问答表
    *   `question_text`: 相似的问法（例如：“怎么退款”和“退款流程”是相似问）

#### B. 向量存储 (Vector Storage)

算法匹配的核心是将文字转化为向量。两个选择：

1.  **独立向量数据库**：如 Milvus, Qdrant, ChromaDB（适合数据量极大）。
2.  **关系库插件（推荐起步方案）**：使用 PostgreSQL 的 `pgvector` 插件。可以在一张表里同时存文本和向量，不用维护两个数据库。

---

### 2. 需要使用什么模型？

**需要使用文本嵌入模型 (Text Embedding Model)。**

使用文本嵌入模型的目的是能够理解 “语义相似度”。

推荐模型：

*   **SBERT**：使用SBERT计算语义相似度。
*   **中文开源 SOTA 模型（首选）**：
    *   **BGE (BAAI General Embedding)**：目前中文效果非常好的模型（如 `bge-m3` 或 `bge-large-zh`）。
    *   **M3E (M3E-base)**：专门针对中文优化的通用嵌入模型。
    *   **Text2Vec**：经典的轻量级中文嵌入模型。

---

### 3. 如何使用 BERT (Embedding 模型) ?

**“离线存储+在线检索”**

#### 流程一：FAQ 录入（离线/后台流程）

1.  **运营录入**：运营在后台输入“标准问”和几个“相似问”。
2.  **向量化 (Embedding)**：后端调用算法服务（BERT 模型），将“标准问”和“相似问”的文本转化成 **Dense Vector**（稠密向量，通常是 768 维或 1024 维的数组）。
3.  **存储**：将 `[问题ID, 问题文本, 向量数据]` 存入数据库（或向量库）。

#### 流程二：用户提问匹配（在线流程）

1.  **用户提问**：用户发送 "我想把东西退了"。
2.  **预处理**：后端先检查缓存，或进行简单的关键词过滤。
3.  **向量化**：调用 BERT 模型，将 "我想把东西退了" 转化为向量 $V_{user}$。
4.  **相似度计算**：
    *   在数据库中，计算 $V_{user}$ 与所有库存问题向量的 **余弦相似度 (Cosine Similarity)**。
    *   逻辑过滤：在 SQL 查询时，必须加上 `WHERE now() BETWEEN start_time AND end_time`，确保只匹配生效时间内的 FAQ。
5.  **阈值判断**：
    *   如果 Top 1 的相似度 > 0.85（阈值可调），直接返回对应的 `answer`。
    *   如果相似度在 0.6 ~ 0.85 之间，返回“您是否想问...？”（推荐相似问题）。
    *   如果低于 0.6，转人工或回复“我没听懂”。

---

### 4. 是否需要使用大模型 (LLM, 如 GPT/Qwen/DeepSeek)？

**非必须，但可以作为“增强插件”。**

需求是 **“将最相似提问的答案返回给用户”**。这是一个经典的 **检索 (Retrieval)** 任务，而不是 **生成 (Generation)** 任务，因此使用 **Embedding + 向量检索** 是最准确、最可控、成本最低的方案。
