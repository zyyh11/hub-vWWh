# 文本分类方法对比

## 1. Regex（正则表达式）

**简介**  
基于规则匹配文本的模式，如 `"北京|上海|广州"` 匹配关键词。属于规则工程，不依赖训练数据。

**优点**  
- 简单、快速、零训练成本  
- 精准匹配特定模式（手机号、邮箱、关键词）  
- 可直接用于生产环境，延迟极低  

**缺点**  
- 不灵活，稍微变动就匹配不到  
- 无法理解语义（“帮我去北京” vs “导航到北京”）  
- 规则维护成本高，文本量大时不适合  

**使用场景**  
- 关键词提取、日志解析、格式固定文本  
- 小规模、业务规则明确的分类  

---

## 2. TF-IDF（Term Frequency – Inverse Document Frequency）

**简介**  
基于词频统计的向量化方法，将文本转换成向量，常与传统 ML 模型（SVM、LR 等）结合。

**优点**  
- 易实现、训练成本低  
- 能处理大规模文本  
- 对关键词敏感，短文本效果好  

**缺点**  
- 不捕捉语序或上下文，无法理解语义  
- 高维稀疏向量，占用内存大  
- 对同义词或拼写敏感（“北京” vs “京城”）  

**使用场景**  
- 文本分类、垃圾邮件识别、新闻分类  
- 数据量中等、语义理解要求不高  

---

## 3. BERT（预训练语言模型）

**简介**  
基于 Transformer 架构，能捕捉上下文语义，支持微调完成分类、问答、NER 等任务。

**优点**  
- 捕捉语义和上下文  
- 支持多任务，少量标注也可微调  
- 表现通常优于传统方法  

**缺点**  
- 模型大，训练和推理成本高  
- 小数据集可能过拟合  
- 部署复杂，需要 GPU/显存  

**使用场景**  
- 意图识别、问答系统、情感分析  
- 高语义理解需求、文本多样化场景  

---

## 4. Prompt（提示工程 / 大语言模型）

**简介**  
通过提示（prompt）利用大语言模型（如 GPT、Qwen）进行生成或分类，无需显式训练。

**优点**  
- 零样本或少样本能力强  
- 处理复杂语义、开放问题灵活  
- 快速扩展新任务，无需重新训练  

**缺点**  
- 推理成本高，依赖大模型  
- 对 prompt 设计敏感，结果可能不稳定  
- 可控性不如传统模型  

**使用场景**  
- 意图识别、开放问答、对话系统  
- 数据少或任务快速迭代场景  

---

## 5. 对比总结表

| 方法      | 优点 | 缺点 | 场景 |
|-----------|------|------|------|
| Regex    | 快、精准、零训练成本 | 不灵活、维护成本高、无语义 | 固定格式文本、关键词匹配 |
| TF-IDF   | 简单、低训练成本、短文本有效 | 无语义、稀疏高维、对同义词敏感 | 文本分类、垃圾邮件识别 |
| BERT     | 捕捉语义上下文、微调强大 | 模型大、训练推理成本高 | 意图识别、问答、情感分析 |
| Prompt  | 零样本/少样本、灵活、扩展方便 | 高成本、依赖 prompt、可控性差 | 少样本任务、快速迭代、开放问答 |

---

## 6. 选择

1. 小任务 / 规则明确 → **Regex**  
2. 中等规模、关键词重要 → **TF-IDF + 传统 ML**  
3. 需要理解语义 → **BERT / GRU / LSTM**  
4. 数据少、任务变化快 → **Prompt / 大语言模型**